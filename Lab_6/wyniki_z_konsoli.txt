
R version 4.1.2 (2021-11-01) -- "Bird Hippie"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> setwd("G:/ATH/Apu/LAB/LAB6/Workspace")
> 
> #install.packages("keras")
> library("keras")
> #install.packages("tensorflow")
> library("tensorflow")
> #install_tensorflow()
> 
> #load data cifar 10
> cifar <- dataset_cifar10()
2022-03-03 19:55:56.857016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2022-03-03 19:55:56.857310: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Loaded Tensorflow version 2.8.0
> 
> x_train <- cifar$train$x
> x_test <- cifar$test$x
> y_train <- cifar$train$y
> y_test <- cifar$test$y
> 
> #--------------------------------------------------- wersja liniowa
> 
> #set up data
> #change matrix shape
> x_train <- array_reshape(x_train, c(nrow(x_train), 3072))
> #normalize
> x_train <- x_train / 255                                  
> 
> x_test <- array_reshape(x_test, c(nrow(x_test), 3072))
> x_test <- x_test / 255
> 
> #set classes
> y_train <- to_categorical(y_train, num_classes = 10)
> y_test <- to_categorical(y_test, num_classes = 10)
> 
> #256 neurons, dropout rate 0.25
> model <- keras_model_sequential() %>%
+   layer_dense(units = 256, activation = "relu", input_shape = c(3072)) %>%   
+   layer_dropout(rate = 0.25) %>%                                            
+   layer_dense(units = 128, activation = "relu") %>%
+   layer_dropout(rate = 0.25) %>%
+   layer_dense(units = 64, activation = "relu") %>%
+   layer_dropout(rate = 0.25) %>%
+   layer_dense(units = 10, activation = "relu")
2022-03-03 19:56:05.852080: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2022-03-03 19:56:05.853614: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2022-03-03 19:56:05.855447: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2022-03-03 19:56:05.856983: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2022-03-03 19:56:05.858514: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2022-03-03 19:56:05.860057: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found
2022-03-03 19:56:05.861610: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2022-03-03 19:56:05.863447: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2022-03-03 19:56:05.863828: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2022-03-03 19:56:05.864604: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
> 
> summary(model)
Model: "sequential"
_______________________________________________________________________________________________________________
 Layer (type)                                    Output Shape                                 Param #          
===============================================================================================================
 dense_3 (Dense)                                 (None, 256)                                  786688           
                                                                                                               
 dropout_2 (Dropout)                             (None, 256)                                  0                
                                                                                                               
 dense_2 (Dense)                                 (None, 128)                                  32896            
                                                                                                               
 dropout_1 (Dropout)                             (None, 128)                                  0                
                                                                                                               
 dense_1 (Dense)                                 (None, 64)                                   8256             
                                                                                                               
 dropout (Dropout)                               (None, 64)                                   0                
                                                                                                               
 dense (Dense)                                   (None, 10)                                   650              
                                                                                                               
===============================================================================================================
Total params: 828,490
Trainable params: 828,490
Non-trainable params: 0
_______________________________________________________________________________________________________________
> 
> #set model parameters
> model %>% compile(
+   loss = "categorical_crossentropy",     #calculate loss
+   optimizer = optimizer_adam(),          #optimization
+   metrics = c("accuracy")                #accuracy
+ )
> 
> #train model
> history <- model %>%
+   fit(
+     x_train, y_train,          #input
+     epochs = 50,               
+     batch_size = 128,          #128 pictures
+     validation_split = 0.15
+   )
Epoch 1/50
333/333 [==============================] - 4s 9ms/step - loss: 2.4510 - accuracy: 0.1074 - val_loss: 2.3022 - val_accuracy: 0.1000
Epoch 2/50
333/333 [==============================] - 3s 8ms/step - loss: 2.2531 - accuracy: 0.1355 - val_loss: 2.1459 - val_accuracy: 0.1732
Epoch 3/50
333/333 [==============================] - 2s 7ms/step - loss: 2.1902 - accuracy: 0.1654 - val_loss: 2.3122 - val_accuracy: 0.0985
Epoch 4/50
333/333 [==============================] - 2s 7ms/step - loss: 2.1972 - accuracy: 0.1565 - val_loss: 2.0953 - val_accuracy: 0.2016
Epoch 5/50
333/333 [==============================] - 2s 7ms/step - loss: 2.1266 - accuracy: 0.1820 - val_loss: 2.0662 - val_accuracy: 0.2199
Epoch 6/50
333/333 [==============================] - 2s 7ms/step - loss: 2.1035 - accuracy: 0.2071 - val_loss: 2.0398 - val_accuracy: 0.2323
Epoch 7/50
333/333 [==============================] - 2s 7ms/step - loss: 2.0642 - accuracy: 0.2319 - val_loss: 2.1302 - val_accuracy: 0.2075
Epoch 8/50
333/333 [==============================] - 2s 7ms/step - loss: 2.0706 - accuracy: 0.2253 - val_loss: 1.9988 - val_accuracy: 0.2501
Epoch 9/50
333/333 [==============================] - 2s 7ms/step - loss: 2.1089 - accuracy: 0.2147 - val_loss: 2.0159 - val_accuracy: 0.2393
Epoch 10/50
333/333 [==============================] - 2s 7ms/step - loss: 2.0607 - accuracy: 0.2296 - val_loss: 1.9770 - val_accuracy: 0.2619
Epoch 11/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9957 - accuracy: 0.2579 - val_loss: 1.9227 - val_accuracy: 0.2821
Epoch 12/50
333/333 [==============================] - 2s 7ms/step - loss: 2.0348 - accuracy: 0.2348 - val_loss: 1.9714 - val_accuracy: 0.2609
Epoch 13/50
333/333 [==============================] - 2s 7ms/step - loss: 2.0149 - accuracy: 0.2476 - val_loss: 1.9273 - val_accuracy: 0.2791
Epoch 14/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9858 - accuracy: 0.2599 - val_loss: 1.9452 - val_accuracy: 0.2853
Epoch 15/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9813 - accuracy: 0.2643 - val_loss: 1.9033 - val_accuracy: 0.2961
Epoch 16/50
333/333 [==============================] - 3s 8ms/step - loss: 1.9422 - accuracy: 0.2769 - val_loss: 1.8850 - val_accuracy: 0.3063
Epoch 17/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9847 - accuracy: 0.2604 - val_loss: 1.8987 - val_accuracy: 0.3004
Epoch 18/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9405 - accuracy: 0.2763 - val_loss: 1.8894 - val_accuracy: 0.2985
Epoch 19/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9611 - accuracy: 0.2703 - val_loss: 1.9910 - val_accuracy: 0.2835
Epoch 20/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9770 - accuracy: 0.2589 - val_loss: 1.8870 - val_accuracy: 0.3112
Epoch 21/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9118 - accuracy: 0.2903 - val_loss: 1.8681 - val_accuracy: 0.3079
Epoch 22/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8929 - accuracy: 0.3008 - val_loss: 1.8459 - val_accuracy: 0.3277
Epoch 23/50
333/333 [==============================] - 3s 8ms/step - loss: 1.8829 - accuracy: 0.3073 - val_loss: 1.8241 - val_accuracy: 0.3319
Epoch 24/50
333/333 [==============================] - 3s 8ms/step - loss: 1.8598 - accuracy: 0.3147 - val_loss: 1.7969 - val_accuracy: 0.3417
Epoch 25/50
333/333 [==============================] - 3s 8ms/step - loss: 1.8491 - accuracy: 0.3216 - val_loss: 1.7962 - val_accuracy: 0.3536
Epoch 26/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8388 - accuracy: 0.3279 - val_loss: 1.7597 - val_accuracy: 0.3644
Epoch 27/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8392 - accuracy: 0.3314 - val_loss: 1.8420 - val_accuracy: 0.3169
Epoch 28/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9700 - accuracy: 0.2726 - val_loss: 1.8432 - val_accuracy: 0.3284
Epoch 29/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8864 - accuracy: 0.3062 - val_loss: 1.7940 - val_accuracy: 0.3487
Epoch 30/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8589 - accuracy: 0.3179 - val_loss: 1.7752 - val_accuracy: 0.3575
Epoch 31/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8553 - accuracy: 0.3198 - val_loss: 1.8105 - val_accuracy: 0.3533
Epoch 32/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8780 - accuracy: 0.3147 - val_loss: 1.7937 - val_accuracy: 0.3588
Epoch 33/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8811 - accuracy: 0.3115 - val_loss: 1.7583 - val_accuracy: 0.3608
Epoch 34/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9381 - accuracy: 0.2893 - val_loss: 1.8559 - val_accuracy: 0.3316
Epoch 35/50
333/333 [==============================] - 3s 8ms/step - loss: 1.9276 - accuracy: 0.2918 - val_loss: 1.8187 - val_accuracy: 0.3443
Epoch 36/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9531 - accuracy: 0.2859 - val_loss: 1.9730 - val_accuracy: 0.2748
Epoch 37/50
333/333 [==============================] - 2s 7ms/step - loss: 2.0056 - accuracy: 0.2567 - val_loss: 1.8705 - val_accuracy: 0.3283
Epoch 38/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9308 - accuracy: 0.2912 - val_loss: 1.8274 - val_accuracy: 0.3475
Epoch 39/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8906 - accuracy: 0.3109 - val_loss: 1.8005 - val_accuracy: 0.3509
Epoch 40/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8777 - accuracy: 0.3121 - val_loss: 1.7821 - val_accuracy: 0.3619
Epoch 41/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8544 - accuracy: 0.3224 - val_loss: 1.7672 - val_accuracy: 0.3577
Epoch 42/50
333/333 [==============================] - 3s 8ms/step - loss: 1.8445 - accuracy: 0.3328 - val_loss: 1.7593 - val_accuracy: 0.3600
Epoch 43/50
333/333 [==============================] - 3s 8ms/step - loss: 1.8261 - accuracy: 0.3332 - val_loss: 1.7572 - val_accuracy: 0.3619
Epoch 44/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8151 - accuracy: 0.3419 - val_loss: 1.7334 - val_accuracy: 0.3689
Epoch 45/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8095 - accuracy: 0.3446 - val_loss: 1.7275 - val_accuracy: 0.3763
Epoch 46/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8430 - accuracy: 0.3306 - val_loss: 1.8388 - val_accuracy: 0.3281
Epoch 47/50
333/333 [==============================] - 2s 7ms/step - loss: 1.9010 - accuracy: 0.3031 - val_loss: 1.8400 - val_accuracy: 0.3456
Epoch 48/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8885 - accuracy: 0.3106 - val_loss: 1.7695 - val_accuracy: 0.3559
Epoch 49/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8418 - accuracy: 0.3270 - val_loss: 1.7572 - val_accuracy: 0.3635
Epoch 50/50
333/333 [==============================] - 2s 7ms/step - loss: 1.8110 - accuracy: 0.3408 - val_loss: 1.7267 - val_accuracy: 0.3763
> 
> #check quality
> model %>% evaluate(x_test, y_test)
313/313 [==============================] - 0s 1ms/step - loss: 1.7073 - accuracy: 0.3812
    loss accuracy 
1.707256 0.381200 
>

R version 4.1.2 (2021-11-01) -- "Bird Hippie"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> setwd("G:/ATH/Apu/LAB/LAB6/Workspace")
> 
> #install.packages("keras")
> library("keras")
> #install.packages("tensorflow")
> library("tensorflow")
> #install_tensorflow()
> cifar <- dataset_cifar10()
2022-03-03 20:01:41.023185: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2022-03-03 20:01:41.023494: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Loaded Tensorflow version 2.8.0
> 
> x_train <- cifar$train$x
> x_test <- cifar$test$x
> y_train <- cifar$train$y
> y_test <- cifar$test$y
> 
> #set up data
> #normalize
> x_train <- x_train / 255                                  
> 
> x_test <- x_test / 255
> 
> #set classes
> y_train <- to_categorical(y_train, num_classes = 10)
> y_test <- to_categorical(y_test, num_classes = 10)
> 
> #create model
> model <- keras_model_sequential() %>%
+   layer_flatten(input_shape = c(32, 32, 3)) %>%
+   layer_dense(units = 128, activation = "relu") %>%
+   layer_dense(units = 10, activation = "softmax")
2022-03-03 20:01:46.435416: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2022-03-03 20:01:46.436988: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2022-03-03 20:01:46.438424: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2022-03-03 20:01:46.439778: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2022-03-03 20:01:46.441181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2022-03-03 20:01:46.442675: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found
2022-03-03 20:01:46.444119: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2022-03-03 20:01:46.445495: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2022-03-03 20:01:46.449972: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2022-03-03 20:01:46.450671: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
> 
> #print model
> summary(model)
Model: "sequential"
_______________________________________________________________________________________________________________
 Layer (type)                                    Output Shape                                 Param #          
===============================================================================================================
 flatten (Flatten)                               (None, 3072)                                 0                
                                                                                                               
 dense_1 (Dense)                                 (None, 128)                                  393344           
                                                                                                               
 dense (Dense)                                   (None, 10)                                   1290             
                                                                                                               
===============================================================================================================
Total params: 394,634
Trainable params: 394,634
Non-trainable params: 0
_______________________________________________________________________________________________________________
> 
> #set model parameters
> model %>% compile(
+   loss = "categorical_crossentropy",      #calculate loss
+   optimizer = optimizer_adam(),           #optimization
+   metrics = c("accuracy")                 #accuracy
+ )
> 
> #train model
> history <- model %>%
+   fit(
+     x_train, y_train,
+     epochs = 50,
+     batch_size = 128,
+     validation_split = 0.15
+   )
Epoch 1/50
333/333 [==============================] - 2s 6ms/step - loss: 1.9610 - accuracy: 0.3019 - val_loss: 1.8519 - val_accuracy: 0.3400
Epoch 2/50
333/333 [==============================] - 2s 5ms/step - loss: 1.7969 - accuracy: 0.3666 - val_loss: 1.8529 - val_accuracy: 0.3307
Epoch 3/50
333/333 [==============================] - 2s 5ms/step - loss: 1.7511 - accuracy: 0.3855 - val_loss: 1.8164 - val_accuracy: 0.3559
Epoch 4/50
333/333 [==============================] - 2s 5ms/step - loss: 1.7266 - accuracy: 0.3886 - val_loss: 1.7560 - val_accuracy: 0.3711
Epoch 5/50
333/333 [==============================] - 2s 5ms/step - loss: 1.6967 - accuracy: 0.4002 - val_loss: 1.7563 - val_accuracy: 0.3733
Epoch 6/50
333/333 [==============================] - 2s 5ms/step - loss: 1.6741 - accuracy: 0.4120 - val_loss: 1.7232 - val_accuracy: 0.3863
Epoch 7/50
333/333 [==============================] - 2s 5ms/step - loss: 1.6603 - accuracy: 0.4129 - val_loss: 1.7718 - val_accuracy: 0.3743
Epoch 8/50
333/333 [==============================] - 2s 5ms/step - loss: 1.6543 - accuracy: 0.4150 - val_loss: 1.6953 - val_accuracy: 0.3943
Epoch 9/50
333/333 [==============================] - 2s 5ms/step - loss: 1.6285 - accuracy: 0.4248 - val_loss: 1.6875 - val_accuracy: 0.4028
Epoch 10/50
333/333 [==============================] - 2s 5ms/step - loss: 1.6221 - accuracy: 0.4263 - val_loss: 1.6428 - val_accuracy: 0.4140
Epoch 11/50
333/333 [==============================] - 2s 5ms/step - loss: 1.6036 - accuracy: 0.4341 - val_loss: 1.6314 - val_accuracy: 0.4196
Epoch 12/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5945 - accuracy: 0.4370 - val_loss: 1.6843 - val_accuracy: 0.4091
Epoch 13/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5843 - accuracy: 0.4400 - val_loss: 1.6411 - val_accuracy: 0.4132
Epoch 14/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5818 - accuracy: 0.4412 - val_loss: 1.6115 - val_accuracy: 0.4269
Epoch 15/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5711 - accuracy: 0.4441 - val_loss: 1.6246 - val_accuracy: 0.4241
Epoch 16/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5633 - accuracy: 0.4465 - val_loss: 1.6114 - val_accuracy: 0.4271
Epoch 17/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5581 - accuracy: 0.4484 - val_loss: 1.6258 - val_accuracy: 0.4189
Epoch 18/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5500 - accuracy: 0.4530 - val_loss: 1.6014 - val_accuracy: 0.4285
Epoch 19/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5397 - accuracy: 0.4550 - val_loss: 1.6096 - val_accuracy: 0.4293
Epoch 20/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5391 - accuracy: 0.4538 - val_loss: 1.8561 - val_accuracy: 0.3364
Epoch 21/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5478 - accuracy: 0.4503 - val_loss: 1.6159 - val_accuracy: 0.4264
Epoch 22/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5249 - accuracy: 0.4584 - val_loss: 1.5859 - val_accuracy: 0.4301
Epoch 23/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5255 - accuracy: 0.4584 - val_loss: 1.5913 - val_accuracy: 0.4264
Epoch 24/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5172 - accuracy: 0.4632 - val_loss: 1.5931 - val_accuracy: 0.4304
Epoch 25/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5187 - accuracy: 0.4642 - val_loss: 1.5761 - val_accuracy: 0.4373
Epoch 26/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5146 - accuracy: 0.4643 - val_loss: 1.7299 - val_accuracy: 0.4068
Epoch 27/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5148 - accuracy: 0.4604 - val_loss: 1.6364 - val_accuracy: 0.4173
Epoch 28/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4981 - accuracy: 0.4703 - val_loss: 1.6064 - val_accuracy: 0.4352
Epoch 29/50
333/333 [==============================] - 2s 5ms/step - loss: 1.5054 - accuracy: 0.4656 - val_loss: 1.5868 - val_accuracy: 0.4375
Epoch 30/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4994 - accuracy: 0.4685 - val_loss: 1.5648 - val_accuracy: 0.4489
Epoch 31/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4893 - accuracy: 0.4700 - val_loss: 1.5846 - val_accuracy: 0.4347
Epoch 32/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4885 - accuracy: 0.4702 - val_loss: 1.5871 - val_accuracy: 0.4336
Epoch 33/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4879 - accuracy: 0.4680 - val_loss: 1.5789 - val_accuracy: 0.4413
Epoch 34/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4857 - accuracy: 0.4725 - val_loss: 1.6009 - val_accuracy: 0.4344
Epoch 35/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4789 - accuracy: 0.4754 - val_loss: 1.5987 - val_accuracy: 0.4403
Epoch 36/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4762 - accuracy: 0.4762 - val_loss: 1.5887 - val_accuracy: 0.4305
Epoch 37/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4683 - accuracy: 0.4783 - val_loss: 1.5829 - val_accuracy: 0.4311
Epoch 38/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4683 - accuracy: 0.4784 - val_loss: 1.6291 - val_accuracy: 0.4280
Epoch 39/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4709 - accuracy: 0.4774 - val_loss: 1.6125 - val_accuracy: 0.4268
Epoch 40/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4683 - accuracy: 0.4787 - val_loss: 1.5972 - val_accuracy: 0.4315
Epoch 41/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4645 - accuracy: 0.4775 - val_loss: 1.5458 - val_accuracy: 0.4444
Epoch 42/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4600 - accuracy: 0.4806 - val_loss: 1.5631 - val_accuracy: 0.4415
Epoch 43/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4570 - accuracy: 0.4811 - val_loss: 1.5987 - val_accuracy: 0.4308
Epoch 44/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4651 - accuracy: 0.4814 - val_loss: 1.5479 - val_accuracy: 0.4428
Epoch 45/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4558 - accuracy: 0.4841 - val_loss: 1.5524 - val_accuracy: 0.4529
Epoch 46/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4518 - accuracy: 0.4833 - val_loss: 1.5764 - val_accuracy: 0.4379
Epoch 47/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4533 - accuracy: 0.4869 - val_loss: 1.6054 - val_accuracy: 0.4292
Epoch 48/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4541 - accuracy: 0.4836 - val_loss: 1.5447 - val_accuracy: 0.4480
Epoch 49/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4479 - accuracy: 0.4854 - val_loss: 1.6199 - val_accuracy: 0.4349
Epoch 50/50
333/333 [==============================] - 2s 5ms/step - loss: 1.4521 - accuracy: 0.4831 - val_loss: 1.5863 - val_accuracy: 0.4397
> 
> #check model quality 
> model %>% evaluate(x_test, y_test)
313/313 [==============================] - 0s 878us/step - loss: 1.5702 - accuracy: 0.4454
    loss accuracy 
1.570245 0.445400 
> 
> #predict
> model %>% predict(x_test) %>% k_argmin()
tf.Tensor([9 6 6 ... 1 8 6], shape=(10000,), dtype=int64)
>